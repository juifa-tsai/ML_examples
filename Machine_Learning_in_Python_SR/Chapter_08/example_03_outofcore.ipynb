{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3. Sentiment training with IMBd data, out-of-core learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import package and function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Alpha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # remove html flag, e.g. <br />\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())+' '.join(emoticons).replace('-','')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"... but the trouble of this production is that it\\'s very far from a good musical.<br /><br />Granted, one can\\'t always expect the witty masters like Sondheim or Bernstein or Porter; yet the music of this piece makes even Andrew Lloyd Webber look witty. It\\'s deadly dull and uninventive (with one or two exceptions) and just after I watched it I couldn\\'t recall a single significant melody - which is rather tragic coming from someone who learned the whole Another Hundred People from three listenings.<br /><br />It is also strangely un-theatrical. It takes place on an incredibly large stage (one really has to feel sorry for those people in front rows who broke their necks in order to see something happening 50 meters on the right or 100 meters on the left) and does absolutely nothing with it. When there\\'s supposed to be one person singing on-stage, that\\'s just what you get - and the rest of the enormeous stage is empty. For me as an aspiring theatre director it was almost painful to watch.<br /><br />The fact remains, Cole Porter seems to have captured the French culture in his works better than these no-talents can ever come close to. And I\\'m puzzled by the popularity of this would-be-legendary musical.\"',\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label\n",
    "# test:\n",
    "next(stream_docs(path='../data/imbd.csv.train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(docs_stream, size):\n",
    "    docs, y = [], []\n",
    "    try: \n",
    "        for _ in range(size):\n",
    "            text, label = next(docs_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_feature=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', random_state=1, n_iter=1)\n",
    "docs_stream = stream_docs(path='../data/imbd.csv.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
